experiment_name,concurrency,payload_file,errors,successes,error_rate,all_prompts_token_count,prompt_token_count_mean,prompt_token_throughput,all_completions_token_count,completion_token_count_mean,completion_token_throughput,transactions,transactions_per_second,transactions_per_minute,latency_mean,instance_type,EndpointName,ModelName,Image,S3Uri,ENDPOINT_SERVER_TIMEOUT,HF_MODEL_ID,MAX_INPUT_LENGTH,MAX_TOTAL_TOKENS,MODEL_CACHE_ROOT,SAGEMAKER_ENV,SAGEMAKER_MODEL_SERVER_WORKERS,SAGEMAKER_PROGRAM,SM_NUM_GPUS
llama2-7b-g5.xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,1,payload_en_1000-2000.jsonl,[],1,0.0,1339,1339.0,1607.37,9,9.0,10.8,1,1.2,72,0.8233720419957535,ml.g5.xlarge,llama-2-7b-g5xlarge-1711143414-275531,meta-textgeneration-llama-2-7b-2024-03-22-21-36-54-275,763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04,s3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-2-7b/artifacts/inference-prepack/v1.0.0/,3600,/opt/ml/model,4095,4096,/opt/ml/model,1,1,inference.py,1
llama2-7b-g5.xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,1,payload_en_1000-2000.jsonl,[],1,0.0,1932,1932.0,451.06,102,102.0,23.81,1,0.23,13,4.257527666995884,ml.g5.xlarge,llama-2-7b-g5xlarge-1711143414-275531,meta-textgeneration-llama-2-7b-2024-03-22-21-36-54-275,763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04,s3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-2-7b/artifacts/inference-prepack/v1.0.0/,3600,/opt/ml/model,4095,4096,/opt/ml/model,1,1,inference.py,1
llama2-7b-g5.xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,1,payload_en_1000-2000.jsonl,[],1,0.0,1154,1154.0,301.38,102,102.0,26.64,1,0.26,15,3.8036598329927074,ml.g5.xlarge,llama-2-7b-g5xlarge-1711143414-275531,meta-textgeneration-llama-2-7b-2024-03-22-21-36-54-275,763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04,s3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-2-7b/artifacts/inference-prepack/v1.0.0/,3600,/opt/ml/model,4095,4096,/opt/ml/model,1,1,inference.py,1
llama2-7b-g5.xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,1,payload_en_1000-2000.jsonl,[],1,0.0,1646,1646.0,2368.51,9,9.0,12.95,1,1.44,86,0.6789358340029139,ml.g5.xlarge,llama-2-7b-g5xlarge-1711143414-275531,meta-textgeneration-llama-2-7b-2024-03-22-21-36-54-275,763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04,s3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-2-7b/artifacts/inference-prepack/v1.0.0/,3600,/opt/ml/model,4095,4096,/opt/ml/model,1,1,inference.py,1
llama2-7b-g5.xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,1,payload_en_1000-2000.jsonl,[],1,0.0,1397,1397.0,1510.79,16,16.0,17.3,1,1.08,64,0.8918582500045886,ml.g5.xlarge,llama-2-7b-g5xlarge-1711143414-275531,meta-textgeneration-llama-2-7b-2024-03-22-21-36-54-275,763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04,s3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-2-7b/artifacts/inference-prepack/v1.0.0/,3600,/opt/ml/model,4095,4096,/opt/ml/model,1,1,inference.py,1
llama2-7b-g5.xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,1,payload_en_1000-2000.jsonl,[],1,0.0,1746,1746.0,1336.27,24,24.0,18.37,1,0.77,46,1.2798885000083828,ml.g5.xlarge,llama-2-7b-g5xlarge-1711143414-275531,meta-textgeneration-llama-2-7b-2024-03-22-21-36-54-275,763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04,s3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-2-7b/artifacts/inference-prepack/v1.0.0/,3600,/opt/ml/model,4095,4096,/opt/ml/model,1,1,inference.py,1
llama2-7b-g5.xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,1,payload_en_1000-2000.jsonl,[],1,0.0,1373,1373.0,2058.86,9,9.0,13.5,1,1.5,90,0.6415108340006554,ml.g5.xlarge,llama-2-7b-g5xlarge-1711143414-275531,meta-textgeneration-llama-2-7b-2024-03-22-21-36-54-275,763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04,s3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-2-7b/artifacts/inference-prepack/v1.0.0/,3600,/opt/ml/model,4095,4096,/opt/ml/model,1,1,inference.py,1
llama2-7b-g5.xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,1,payload_en_1000-2000.jsonl,[],1,0.0,1598,1598.0,2819.71,5,5.0,8.82,1,1.76,105,0.5416424160066526,ml.g5.xlarge,llama-2-7b-g5xlarge-1711143414-275531,meta-textgeneration-llama-2-7b-2024-03-22-21-36-54-275,763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04,s3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-2-7b/artifacts/inference-prepack/v1.0.0/,3600,/opt/ml/model,4095,4096,/opt/ml/model,1,1,inference.py,1
llama2-7b-g5.xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,1,payload_en_1000-2000.jsonl,[],1,0.0,1743,1743.0,418.16,102,102.0,24.47,1,0.24,14,4.143161708998377,ml.g5.xlarge,llama-2-7b-g5xlarge-1711143414-275531,meta-textgeneration-llama-2-7b-2024-03-22-21-36-54-275,763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04,s3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-2-7b/artifacts/inference-prepack/v1.0.0/,3600,/opt/ml/model,4095,4096,/opt/ml/model,1,1,inference.py,1
llama2-7b-g5.xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,1,payload_en_1000-2000.jsonl,[],1,0.0,1539,1539.0,379.18,102,102.0,25.13,1,0.25,15,4.039461584005039,ml.g5.xlarge,llama-2-7b-g5xlarge-1711143414-275531,meta-textgeneration-llama-2-7b-2024-03-22-21-36-54-275,763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04,s3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-2-7b/artifacts/inference-prepack/v1.0.0/,3600,/opt/ml/model,4095,4096,/opt/ml/model,1,1,inference.py,1
llama2-7b-g5.xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,1,payload_en_1000-2000.jsonl,[],1,0.0,1695,1695.0,407.96,102,102.0,24.55,1,0.24,14,4.123766958000488,ml.g5.xlarge,llama-2-7b-g5xlarge-1711143414-275531,meta-textgeneration-llama-2-7b-2024-03-22-21-36-54-275,763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04,s3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-2-7b/artifacts/inference-prepack/v1.0.0/,3600,/opt/ml/model,4095,4096,/opt/ml/model,1,1,inference.py,1
llama2-7b-g5.xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,1,payload_en_1000-2000.jsonl,[],1,0.0,1421,1421.0,354.61,102,102.0,25.45,1,0.25,15,3.9826818330038805,ml.g5.xlarge,llama-2-7b-g5xlarge-1711143414-275531,meta-textgeneration-llama-2-7b-2024-03-22-21-36-54-275,763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04,s3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-2-7b/artifacts/inference-prepack/v1.0.0/,3600,/opt/ml/model,4095,4096,/opt/ml/model,1,1,inference.py,1
llama2-7b-g5.xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,1,payload_en_1000-2000.jsonl,[],1,0.0,1918,1918.0,452.08,102,102.0,24.04,1,0.24,14,4.217987625001115,ml.g5.xlarge,llama-2-7b-g5xlarge-1711143414-275531,meta-textgeneration-llama-2-7b-2024-03-22-21-36-54-275,763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04,s3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-2-7b/artifacts/inference-prepack/v1.0.0/,3600,/opt/ml/model,4095,4096,/opt/ml/model,1,1,inference.py,1
llama2-7b-g5.xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,1,payload_en_1000-2000.jsonl,[],1,0.0,1910,1910.0,448.72,102,102.0,23.96,1,0.23,13,4.220529291997082,ml.g5.xlarge,llama-2-7b-g5xlarge-1711143414-275531,meta-textgeneration-llama-2-7b-2024-03-22-21-36-54-275,763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04,s3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-2-7b/artifacts/inference-prepack/v1.0.0/,3600,/opt/ml/model,4095,4096,/opt/ml/model,1,1,inference.py,1
llama2-7b-g5.xlarge-huggingface-pytorch-tgi-inference-2.0.1-tgi1.1.0,1,payload_en_1000-2000.jsonl,[],1,0.0,1939,1939.0,451.3,102,102.0,23.74,1,0.23,13,4.264153875003103,ml.g5.xlarge,llama-2-7b-g5xlarge-1711143414-275531,meta-textgeneration-llama-2-7b-2024-03-22-21-36-54-275,763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04,s3://jumpstart-private-cache-prod-us-east-1/meta-textgeneration/meta-textgeneration-llama-2-7b/artifacts/inference-prepack/v1.0.0/,3600,/opt/ml/model,4095,4096,/opt/ml/model,1,1,inference.py,1
